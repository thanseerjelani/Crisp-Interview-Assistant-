# AI Interview Platform

An intelligent full-stack interview application powered by Google's Gemini 2.0 Flash that autonomously conducts technical assessments with AI-driven question generation, real-time answer evaluation, and comprehensive candidate analytics.

ğŸ”— **[Live Demo](https://crisp-interview-assistant.netlify.app/)** | ğŸ“‚ **[GitHub Repository](https://github.com/thanseerjelani/Crisp-Interview-Assistant-)**

## ğŸš€ What I Built

I developed this GenAI-powered platform to completely automate technical interviews using Google's latest Gemini 2.0 Flash model. The system intelligently generates contextual questions, evaluates candidate responses in real-time, and provides detailed performance analytics - all powered by generative AI.

### For Candidates

- **Smart Resume Processing**: Upload PDF/DOCX resumes with automatic data extraction
- **Interactive Onboarding**: Conversational AI interface fills in missing information
- **AI-Generated Questions**: 6 dynamically created questions that adapt to context (Easy â†’ Medium â†’ Hard)
- **Time Management**: Built-in timers with auto-submission (20s/60s/120s based on difficulty)
- **AI-Powered Evaluation**: Real-time scoring with personalized, AI-generated feedback
- **Session Recovery**: Automatic save allows candidates to continue interrupted interviews

### For Interviewers

- **Centralized Dashboard**: Searchable, sortable candidate database
- **Deep Insights**: Full interview transcripts with AI-generated analysis
- **Visual Metrics**: Color-coded performance badges and percentage scoring
- **AI Summary Reports**: Comprehensive candidate assessments generated by Gemini

## ğŸ’¡ Technical Approach

### GenAI Integration with Gemini 2.0 Flash

I implemented Google's Gemini 2.0 Flash model as the core AI engine:

**Dynamic Question Generation**

- Context-aware prompt engineering for difficulty-specific questions
- Deduplication logic to avoid repetitive questions
- Temperature-controlled generation (0.7) for balanced creativity
- Max 15-word constraint for concise, professional questions

**Intelligent Answer Evaluation**

- Multi-factor AI analysis: content depth, technical accuracy, code examples
- Structured prompt format for consistent scoring
- AI-generated personalized feedback for each response
- Difficulty-adjusted scoring thresholds

**Smart Summary Generation**

- Performance analysis across all difficulty levels
- Strength/weakness identification using AI
- Hiring recommendation generation
- Professional report formatting

### Three-Tier Fallback Architecture

I designed a robust system that never fails:

**Tier 1: Gemini AI (Primary)**

- Real-time question generation via Gemini API
- Context-aware evaluation with structured prompts
- Retry logic with exponential backoff for rate limits

**Tier 2: Intelligent Fallback Algorithm**

```typescript
// Algorithmic evaluation when API unavailable
- Multi-dimensional answer analysis
- Technical term detection (50+ terms)
- Code example recognition
- Complexity scoring with weighted factors
```

**Tier 3: Curated Question Bank**

- Hand-crafted questions for each difficulty level
- React, Node.js, JavaScript, TypeScript coverage
- Ensures interview quality even offline

### State Architecture

Redux Toolkit with persistence for:

- Type-safe AI response handling
- Automatic localStorage synchronization
- Optimistic UI updates during AI calls
- Loading state management for async operations

## ğŸ› ï¸ Tech Stack

**GenAI & APIs**

- Google Gemini 2.0 Flash API (generative AI)
- Prompt engineering for structured outputs
- Rate limit handling with retry logic

**Frontend Framework**

- React 18 with TypeScript
- Vite for development
- Tailwind CSS + shadcn/ui

**State Management**

- Redux Toolkit for predictable state
- Redux Persist for session continuity

**Document Processing**

- pdfjs-dist for PDF parsing
- mammoth for DOCX handling

## âš¡ Getting Started

```bash
# Clone and navigate
git clone https://github.com/thanseerjelani/Crisp-Interview-Assistant-
cd Crisp-Interview-Assistant-

# Install dependencies
npm install

# Add your Gemini API key (get it from Google AI Studio)
echo "VITE_GEMINI_API_KEY=your-key-here" > .env

# Launch development server
npm run dev
```

Visit `http://localhost:5173` to see it in action.

**Get Gemini API Key**: Visit [Google AI Studio](https://aistudio.google.com/app/apikey) to get your free API key.

## ğŸ—ï¸ Architecture Decisions

### Why Gemini 2.0 Flash?

I chose Google's Gemini 2.0 Flash because:

- **Speed**: Fastest response times for real-time evaluation
- **Cost-effective**: Free tier with generous limits
- **Quality**: Excellent at structured output generation
- **Reliability**: Built-in retry handling for rate limits
- **Latest tech**: Cutting-edge generative AI capabilities

### Prompt Engineering Strategy

My prompts are designed for consistency:

**Question Generation Prompt**:

```typescript
"Generate ONE short ${difficulty} question for Full Stack Developer.
Requirements:
- Maximum 15 words
- Clear and specific
- One question only
- No explanations"
```

**Evaluation Prompt**:

```typescript
"Evaluate this answer.
Format:
SCORE: [0-X]
FEEDBACK: [2 short sentences]"
```

This structured approach ensures parseable, consistent AI responses.

### Resume Parsing Pipeline

```typescript
File Upload â†’ Format Detection (PDF/DOCX)
           â†“
     Text Extraction
           â†“
  Pattern Recognition (Email, Phone, Name)
           â†“
    Structured Data
```

### Interview State Flow

```
START â†’ UPLOAD â†’ AI_COLLECTION â†’ AI_INTERVIEW â†’ AI_SUMMARY
  â†“        â†“            â†“              â†“            â†“
 Idle   Parsing   AI Chat      AI Questions   AI Report
```

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ui/              # Reusable UI components
â”‚   â”œâ”€â”€ interviewee/     # Candidate-facing features
â”‚   â””â”€â”€ interviewer/     # Dashboard components
â”œâ”€â”€ store/
â”‚   â”œâ”€â”€ types.ts         # TypeScript definitions
â”‚   â”œâ”€â”€ slices/          # Redux state slices
â”‚   â””â”€â”€ index.ts         # Store configuration
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ gemini.service.ts      # Gemini AI integration
â”‚   â””â”€â”€ resumeParser.service.ts # Document parsing
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ validators.ts    # Input validation
â”‚   â””â”€â”€ helpers.ts       # Utility functions
â””â”€â”€ pages/               # Route components
```

## ğŸ§ª Testing Coverage

Tested with real Gemini AI integration:

- âœ… AI question generation across all difficulties
- âœ… AI answer evaluation with various response types
- âœ… AI summary generation with different scores
- âœ… Rate limit handling and retry logic
- âœ… Fallback activation when API unavailable
- âœ… Resume parsing (PDF/DOCX)
- âœ… Complete interview flow with AI
- âœ… State persistence across refreshes
- âœ… Mobile responsiveness

## ğŸš€ Deployment

**Netlify** (Current):

```bash
npm run build
netlify deploy --prod
```

Add environment variable `VITE_GEMINI_API_KEY` in Netlify dashboard.

**Vercel**:

```bash
vercel --prod
```

Add environment variable in Vercel project settings.

## ğŸ¯ Future Roadmap

AI-powered enhancements I'm considering:

- Multi-language interview support using Gemini
- Voice-based interviews with speech-to-text
- AI-powered candidate ranking and comparison
- Custom interview templates with AI adaptation
- Export functionality (CSV/PDF reports)
- Video recording with AI transcript analysis

## ğŸ’» Key Implementation Details

### Gemini API Integration

```typescript
// Retry logic with exponential backoff
for (let attempt = 0; attempt < retries; attempt++) {
  if (attempt > 0) {
    await delay(2000 * attempt); // 2s, 4s delays
  }
  // API call with structured prompt
}
```

### Intelligent Fallback Evaluation

When AI is unavailable, my algorithm analyzes:

```typescript
finalScore = (
  baseScore(wordCount, structure) Ã— 0.4 +
  technicalTerms(50+ vocabulary) Ã— 0.3 +
  codeExamples(pattern detection) Ã— 0.3
) Ã— difficultyMultiplier
```

### Performance Optimizations

- Lazy loading for faster initial render
- Debounced API calls to prevent rate limits
- Strategic delay between AI requests (1-2s)
- Route-based code splitting
- Memoized components for expensive renders

## ğŸ“ Development Philosophy

Built with GenAI best practices:

- Structured prompt engineering for consistent outputs
- Graceful degradation when AI unavailable
- Rate limit handling with retry logic
- Type-safe AI response parsing
- Comprehensive error boundaries

## ğŸ¤– GenAI Techniques Used

1. **Prompt Engineering**: Structured prompts for parseable outputs
2. **Temperature Control**: 0.7 for balanced creativity/consistency
3. **Output Constraints**: Token limits and format specifications
4. **Context Management**: Previous questions tracking
5. **Retry Strategies**: Exponential backoff for rate limits
6. **Fallback Systems**: Non-AI algorithms as backup

## ğŸ“„ License

MIT License - feel free to use and modify

---

**Developed by Thanseer Jelani**

_GenAI Project showcasing: Gemini 2.0 Flash integration â€¢ Prompt engineering â€¢ AI evaluation systems â€¢ Fallback architecture â€¢ Full-stack development_
